import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¼é¹…åˆ†ç±»é¢„æµ‹",
    page_icon="ğŸ§",
    layout="wide"
)

# åŠ è½½å›¾ç‰‡
def load_logo():
    logo_path = 'public\rigth_logo.png'
    if os.path.exists(logo_path):
        return Image.open(logo_path)
    return None

# åŠ è½½ä¼é¹…å›¾ç‰‡
def load_penguin_image(species):
    image_paths = {
        "é˜¿å¾·åˆ©ä¼é¹…": "public\é˜¿å¾·åˆ©ä¼é¹….png",
        "å¸½å¸¦ä¼é¹…": "public\å¸½å¸¦ä¼é¹….png",
        "å·´å¸ƒäºšä¼é¹…": "public\å·´å¸ƒäºšä¼é¹….png"
    }
    
    if species in image_paths:
        image_path = image_paths[species]
        if os.path.exists(image_path):
            return Image.open(image_path)
    return None

# åŠ è½½æ•°æ®
def load_data():
    data_path = "public\ï¼ˆä¼é¹…è¯†åˆ«æ•°æ®ï¼‰penguins-chinese.csv"
    try:
        df = pd.read_csv(data_path, encoding='gbk')
        df = df.dropna()
        return df
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None

# è®­ç»ƒæ¨¡å‹
def train_model(df):
    # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
    X = df[['å–™çš„é•¿åº¦', 'å–™çš„æ·±åº¦', 'ç¿…è†€çš„é•¿åº¦', 'èº«ä½“è´¨é‡']]
    y = df['ä¼é¹…çš„ç§ç±»']
    
    # ç¼–ç æ ‡ç­¾
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    
    # è®­ç»ƒæ¨¡å‹
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y_encoded)
    
    return model, le

# ä¸»åº”ç”¨
def main():
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("æ´»åŠ¨é€‰é¡¹")
        if load_logo():
            st.image(load_logo(), width=100)
        st.write("---")
        st.write("ç‚¹å‡»å·¦ä¾§çš„æ´»åŠ¨é€‰é¡¹ï¼Œæ‰å¯ä»¥ç»§ç»­é¢„æµ‹")
        
        # æ´»åŠ¨é€‰é¡¹
        activity = st.selectbox(
            "é€‰æ‹©æ´»åŠ¨",
            ["ä¼é¹…åˆ†ç±»é¢„æµ‹", "å…¶ä»–æ´»åŠ¨1", "å…¶ä»–æ´»åŠ¨2", "å…¶ä»–æ´»åŠ¨3"]
        )

    # ä¸»å†…å®¹åŒºåŸŸ
    st.title("ğŸ§ é¢„æµ‹ä¼é¹…åˆ†ç±»")
    st.write("ä½ å¯ä»¥é€šè¿‡è°ƒæ•´ä»¥ä¸‹å‚æ•°æ¥é¢„æµ‹ä¼é¹…çš„åˆ†ç±»ï¼Œæˆ‘ä»¬å°†æ ¹æ®æœºå™¨å­¦ä¹ æ¨¡å‹ä¸ºä½ é¢„æµ‹ç»“æœï¼")
    
    # åŠ è½½æ•°æ®å’Œè®­ç»ƒæ¨¡å‹
    df = load_data()
    if df is None:
        return
    
    model, le = train_model(df)

    # é¢„æµ‹æ‰§è¡Œæ¨¡å‹
    st.subheader("é¢„æµ‹æ‰§è¡Œæ¨¡å‹")
    st.write("è¯·é€‰æ‹©è¦ä½¿ç”¨çš„é¢„æµ‹æ¨¡å‹ï¼š")
    
    model_option = st.radio(
        "é€‰æ‹©æ¨¡å‹",
        ["éšæœºæ£®æ—æ¨¡å‹", "æ”¯æŒå‘é‡æœºæ¨¡å‹", "å†³ç­–æ ‘æ¨¡å‹"]
    )
    
    # å…­ä¸ªè¾“å…¥é€‰é¡¹
    st.subheader("è¾“å…¥å‚æ•°")
    
    # é€‰é¡¹1: ä¼é¹…æ –æ¯çš„å²›å±¿
    island = st.selectbox(
        "ä¼é¹…æ –æ¯çš„å²›å±¿",
        df['ä¼é¹…æ –æ¯çš„å²›å±¿'].unique()
    )
    
    # é€‰é¡¹2: æ€§åˆ«
    gender = st.selectbox(
        "æ€§åˆ«",
        df['æ€§åˆ«'].unique()
    )
    
    # é€‰é¡¹3: å–™çš„é•¿åº¦
    bill_length = st.slider(
        "å–™çš„é•¿åº¦ (mm)",
        min_value=float(df['å–™çš„é•¿åº¦'].min()),
        max_value=float(df['å–™çš„é•¿åº¦'].max()),
        value=float(df['å–™çš„é•¿åº¦'].mean()),
        step=0.1
    )
    
    # é€‰é¡¹4: å–™çš„æ·±åº¦
    bill_depth = st.slider(
        "å–™çš„æ·±åº¦ (mm)",
        min_value=float(df['å–™çš„æ·±åº¦'].min()),
        max_value=float(df['å–™çš„æ·±åº¦'].max()),
        value=float(df['å–™çš„æ·±åº¦'].mean()),
        step=0.1
    )
    
    # é€‰é¡¹5: ç¿…è†€çš„é•¿åº¦
    flipper_length = st.slider(
        "ç¿…è†€çš„é•¿åº¦ (mm)",
        min_value=float(df['ç¿…è†€çš„é•¿åº¦'].min()),
        max_value=float(df['ç¿…è†€çš„é•¿åº¦'].max()),
        value=float(df['ç¿…è†€çš„é•¿åº¦'].mean()),
        step=1.0
    )
    
    # é€‰é¡¹6: èº«ä½“è´¨é‡
    body_mass = st.slider(
        "èº«ä½“è´¨é‡ (g)",
        min_value=float(df['èº«ä½“è´¨é‡'].min()),
        max_value=float(df['èº«ä½“è´¨é‡'].max()),
        value=float(df['èº«ä½“è´¨é‡'].mean()),
        step=50.0
    )
    
    # é¢„æµ‹æŒ‰é’®
    if st.button("å¼€å§‹é¢„æµ‹"):
        # ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹è¿›è¡Œé¢„æµ‹
        features = np.array([[bill_length, bill_depth, flipper_length, body_mass]])
        prediction_encoded = model.predict(features)[0]
        prediction = le.inverse_transform([prediction_encoded])[0]
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.subheader("é¢„æµ‹ç»“æœ")
        
        # æ˜¾ç¤ºä½¿ç”¨çš„æ¨¡å‹
        st.write(f"ä½¿ç”¨çš„æ¨¡å‹: {model_option}")
        
        # æ˜ å°„å…³ç³»å®ä¾‹
        st.subheader("æ˜ å°„å…³ç³»å®ä¾‹")
        
        mapping_result = {
            "é¢„æµ‹å‡ºçš„ä¼é¹…ç±»åˆ«ï¼ˆç¼–ç ï¼‰": prediction_encoded,
            "è½¬æ¢ä¸ºæ•°æ®é¢„å¤„ç†çš„æ ¼å¼": f"[{bill_length}, {bill_depth}, {flipper_length}, {body_mass}]",
            "é¢„æµ‹å‡ºçš„ä¼é¹…åç§°": prediction,
        }
        
        for key, value in mapping_result.items():
            st.write(f"{key}: {value}")
        
        # æ˜¾ç¤ºå¯¹åº”ä¼é¹…å›¾ç‰‡
        st.subheader("é¢„æµ‹å‡ºçš„ä¼é¹…å›¾ç‰‡")
        penguin_image = load_penguin_image(prediction)
        if penguin_image:
            st.image(penguin_image, caption=prediction, width=200)
        else:
            st.write("æœªæ‰¾åˆ°å¯¹åº”ä¼é¹…å›¾ç‰‡")

# è¿è¡Œåº”ç”¨
if __name__ == '__main__':
    main()