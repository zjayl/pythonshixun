import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import requests
from bs4 import BeautifulSoup

st.set_page_config(
    page_title="ç»¼åˆç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ«",
    layout="wide"
)

with st.sidebar:
    st.title("ğŸ« ç»¼åˆç®¡ç†ç³»ç»Ÿ")
    
    nav = st.radio(
        "å¯¼èˆªèœå•",
        ["é¦–é¡µ", "ä¸ªäººç®€å†ç”Ÿæˆå™¨", "ç…§ç‰‡åˆ‡æ¢å™¨", "ç¾é£Ÿæ•°æ®ä»ªè¡¨ç›˜", "å­¦ç”Ÿæ•°å­—æ¡£æ¡ˆ"]
    )

if nav == "é¦–é¡µ":
    st.title("å¹¿è¥¿èŒä¸šå¸ˆèŒƒå­¦é™¢")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.image("./public/2021031764.jpg", use_column_width=True)
    
    with col2:
        st.subheader("å­¦æ ¡ç®€ä»‹")
        st.write("""
        å¹¿è¥¿èŒä¸šå¸ˆèŒƒå­¦é™¢ï¼ˆåŸå¹¿è¥¿ç»æµç®¡ç†å¹²éƒ¨å­¦é™¢ï¼‰åè½äºå¹¿è¥¿å—å®å¸‚é£æ™¯ç§€ä¸½çš„é‚•æ±Ÿä¹‹æ»¨ã€ç›¸æ€æ¹–ç•”ï¼Œ
        æ˜¯è‡ªæ²»åŒºäººæ°‘æ”¿åºœç›´å±ã€è‡ªæ²»åŒºæ•™è‚²å…ä¸»ç®¡çš„å…¬åŠå…¨æ—¥åˆ¶æ™®é€šæœ¬ç§‘å­¦æ ¡ï¼Œè‡´åŠ›äºåŸ¹å…»é€‚åº”ç»æµç¤¾ä¼šå‘å±•éœ€è¦çš„é«˜ç´ è´¨åº”ç”¨å‹ã€æŠ€æœ¯æŠ€èƒ½å‹äººæ‰èŒä¸šæ•™è‚²å¸ˆèµ„ã€‚
        """)
        
        st.subheader("å­¦æ ¡å†å²")
        st.write("""
        å­¦æ ¡å‰èº«ä¸ºå¹¿è¥¿ç»æµç®¡ç†å¹²éƒ¨å­¦é™¢ï¼Œåˆ›å»ºäº1951å¹´çš„å¹¿è¥¿çœè¡Œæ”¿å¹²éƒ¨è®­ç»ƒç­ï¼Œ
        æ˜¯å¹¿è¥¿ç»æµç®¡ç†äººæ‰çš„æ‘‡ç¯®å’ŒåŸºåœ°ï¼Œä¸ºå¹¿è¥¿ç»æµå»ºè®¾å’Œå‘å±•åšå‡ºäº†ä¸å¯ç£¨ç­çš„çªå‡ºè´¡çŒ®ã€‚
        """)
    
    st.subheader("å­¦é™¢æ¦‚å†µ")
    tab1, tab2, tab3 = st.tabs(["å¸ˆèµ„åŠ›é‡", "å­¦ç§‘ä¸“ä¸š", "æ•™å­¦æˆæœ"])
    
    with tab1:
        st.write("æˆ‘æ ¡æ‹¥æœ‰ä¸€æ”¯é«˜ç´ è´¨æ•™å¸ˆé˜Ÿä¼ï¼Œå…¶ä¸­æ•™æˆã€å‰¯æ•™æˆç­‰é«˜çº§èŒç§°æ•™å¸ˆå æ¯”è¶…è¿‡40%")
        teachers_data = {
            "èŒç§°": ["æ•™æˆ", "å‰¯æ•™æˆ", "è®²å¸ˆ", "åŠ©æ•™"],
            "äººæ•°": [52, 127, 245, 68]
        }
        df_teachers = pd.DataFrame(teachers_data)
        st.bar_chart(df_teachers.set_index("èŒç§°"))
    
    with tab2:
        st.write("å­¦æ ¡è®¾æœ‰12ä¸ªäºŒçº§å­¦é™¢ï¼Œæ¶µç›–ç»æµå­¦ã€ç®¡ç†å­¦ã€å·¥å­¦ã€ç†å­¦ã€æ•™è‚²å­¦ç­‰å…«å¤§å­¦ç§‘")
        with st.expander("æŸ¥çœ‹æ‰€æœ‰ä¸“ä¸š"):
            st.write("- ç»æµä¸ç®¡ç†å­¦é™¢ï¼šç»æµå­¦ã€é‡‘èå­¦ã€ä¼šè®¡å­¦ã€å¸‚åœºè¥é”€")
            st.write("- ä¿¡æ¯å·¥ç¨‹å­¦é™¢ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ã€è½¯ä»¶å·¥ç¨‹ã€ç‰©è”ç½‘å·¥ç¨‹")
            st.write("- æ™ºèƒ½åˆ¶é€ å­¦é™¢ï¼šæœºæ¢°è®¾è®¡åˆ¶é€ åŠå…¶è‡ªåŠ¨åŒ–ã€ç”µæ°”å·¥ç¨‹åŠå…¶è‡ªåŠ¨åŒ–")
            st.write("- æ•™è‚²å­¦é™¢ï¼šæ•™è‚²å­¦ã€å¿ƒç†å­¦ã€å­¦å‰æ•™è‚²")
    
    with tab3:
        st.write("è¿‘å¹´æ¥ï¼Œå­¦æ ¡è·å¾—å›½å®¶çº§æ•™å­¦æˆæœå¥–2é¡¹ï¼Œè‡ªæ²»åŒºçº§æ•™å­¦æˆæœå¥–15é¡¹")
        achievements = {
            "å¹´ä»½": [2018, 2019, 2020, 2021, 2022, 2023],
            "æˆæœæ•°é‡": [2, 3, 2, 3, 2, 3]
        }
        df_achievements = pd.DataFrame(achievements)
        st.line_chart(df_achievements.set_index("å¹´ä»½"))

elif nav == "ä¸ªäººç®€å†ç”Ÿæˆå™¨":
    st.title("ä¸ªäººç®€å†ç”Ÿæˆå™¨")
    
    left_col, right_col = st.columns(2)
    
    with left_col:
        st.header("ä¸ªäººä¿¡æ¯è¡¨å•")
        
        name = st.text_input("å§“å")
        gender = st.radio("æ€§åˆ«", ["ç”·", "å¥³"])
        age = st.number_input("å¹´é¾„", min_value=18, max_value=100, value=25)
        phone = st.text_input("ç”µè¯")
        email = st.text_input("é‚®ç®±")
        location = st.text_input("åœ°å€")
        
        st.subheader("ä¸ªäººç®€ä»‹")
        bio = st.text_area("è¯·è¾“å…¥ä¸ªäººç®€ä»‹", height=100)
        
        st.subheader("æŠ€èƒ½")
        skills = {
            "Python": st.slider("Python", 0, 100, 85),
            "JavaScript": st.slider("JavaScript", 0, 100, 75),
            "HTML/CSS": st.slider("HTML/CSS", 0, 100, 90),
            "React": st.slider("React", 0, 100, 70),
            "Node.js": st.slider("Node.js", 0, 100, 65)
        }
        
        st.subheader("å·¥ä½œç»éªŒ")
        company = st.text_input("å…¬å¸åç§°")
        position = st.text_input("èŒä½")
        start_date = st.date_input("å¼€å§‹æ—¥æœŸ")
        end_date = st.date_input("ç»“æŸæ—¥æœŸ")
        experience = st.text_area("å·¥ä½œæè¿°", height=100)
    
    with right_col:
        st.header("ç®€å†å®æ—¶é¢„è§ˆ")
        
        st.subheader(name)
        st.write(f"{gender} | {age}å²")
        st.write(f"ç”µè¯: {phone}")
        st.write(f"é‚®ç®±: {email}")
        st.write(f"åœ°å€: {location}")
        
        st.subheader("ä¸ªäººç®€ä»‹")
        st.write(bio if bio else "è¯·å¡«å†™ä¸ªäººç®€ä»‹")
        
        st.subheader("æŠ€èƒ½")
        for skill, level in skills.items():
            st.write(f"{skill}: {level}%")
            st.progress(level)
        
        st.subheader("å·¥ä½œç»éªŒ")
        st.write(f"{company} - {position}")
        st.write(f"{start_date} è‡³ {end_date}")
        st.write(experience if experience else "è¯·å¡«å†™å·¥ä½œæè¿°")
    
    if st.button("ä¿å­˜ç®€å†"):
        st.success("ç®€å†å·²ä¿å­˜!")

elif nav == "ç…§ç‰‡åˆ‡æ¢å™¨":
    st.title("ç…§ç‰‡åˆ‡æ¢å™¨")
    
    photos_data = [
        {
            "url": "https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80",
            "caption": "å¯çˆ±çš„æ©˜çŒ«ï¼Œé˜³å…‰ç…§å°„ä¸‹æ˜¾å¾—æ ¼å¤–æ¸©æš–"
        },
        {
            "url": "https://images.unsplash.com/photo-1548199973-03cce0bbc87b?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80",
            "caption": "é»‘ç™½çŒ«å’ªï¼Œä¸“æ³¨çš„çœ¼ç¥"
        },
        {
            "url": "https://images.unsplash.com/photo-1511882150382-421056c89033?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2069&q=80",
            "caption": "å°å¥¶çŒ«ï¼Œå¥½å¥‡å¿ƒæ—ºç››çš„æ ·å­"
        },
        {
            "url": "https://images.unsplash.com/photo-1526336024174-e58f5cdd8e13?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80",
            "caption": "è“çœ¼ç›çŒ«å’ªï¼Œå®‰é™åœ°æ³¨è§†ç€è¿œæ–¹"
        }
    ]
    
    if 'current_index' not in st.session_state:
        st.session_state.current_index = 0
    
    current_photo = photos_data[st.session_state.current_index]
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.image(current_photo["url"], width=600)
        st.caption(current_photo["caption"])
        st.text(f"{st.session_state.current_index + 1} / {len(photos_data)}")
        
        btn_col1, btn_col2 = st.columns(2)
        with btn_col1:
            if st.button("ä¸Šä¸€å¼ "):
                st.session_state.current_index = (st.session_state.current_index - 1) % len(photos_data)
                st.rerun()
        
        with btn_col2:
            if st.button("ä¸‹ä¸€å¼ "):
                st.session_state.current_index = (st.session_state.current_index + 1) % len(photos_data)
                st.rerun()

elif nav == "ç¾é£Ÿæ•°æ®ä»ªè¡¨ç›˜":
    st.title("å—å®ç¾é£Ÿæ•°æ®ä»ªè¡¨ç›˜")
    
    def crawl_restaurant_data():
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/136.0.0.0 Safari/537.36'}
        url = "https://example.com/nanning-food"
        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            response.encoding = 'utf-8'
        except:
            return [
                {"é¤å…": "æ˜Ÿè‰ºä¼šå°ä¸å¿˜", "ç±»å‹": "ä¸­é¤", "è¯„åˆ†": 4.2, "äººå‡æ¶ˆè´¹(å…ƒ)": 15},
                {"é¤å…": "é«˜å³°æŸ æª¬é¸­", "ç±»å‹": "ä¸­é¤", "è¯„åˆ†": 4.5, "äººå‡æ¶ˆè´¹(å…ƒ)": 20},
                {"é¤å…": "å¤è®°è€å‹ç²‰", "ç±»å‹": "å¿«é¤", "è¯„åˆ†": 4.0, "äººå‡æ¶ˆè´¹(å…ƒ)": 25},
                {"é¤å…": "å¥½å‹ç¼˜", "ç±»å‹": "è‡ªåŠ©é¤", "è¯„åˆ†": 4.7, "äººå‡æ¶ˆè´¹(å…ƒ)": 35},
                {"é¤å…": "è¥¿å†·ç‰›æ’åº—", "ç±»å‹": "è¥¿é¤", "è¯„åˆ†": 4.3, "äººå‡æ¶ˆè´¹(å…ƒ)": 50}
            ]
        
        soup = BeautifulSoup(response.text, 'lxml')
        restaurant_list = []
        for item in soup.find_all('div', class_='shop-item'):
            shop_data = {}
            shop_data["é¤å…"] = item.find('h3', class_='shop-name').get_text().strip() if item.find('h3', class_='shop-name') else "æœªçŸ¥"
            shop_data["ç±»å‹"] = item.find('span', class_='shop-type').get_text().strip() if item.find('span', class_='shop-type') else "æœªçŸ¥"
            score = item.find('span', class_='shop-score').get_text().strip() if item.find('span', class_='shop-score') else "0"
            shop_data["è¯„åˆ†"] = float(score) if score.replace('.','').isdigit() else 0.0
            price = item.find('span', class_='shop-price').get_text().strip().replace('äººå‡Â¥','') if item.find('span', class_='shop-price') else "0"
            shop_data["äººå‡æ¶ˆè´¹(å…ƒ)"] = int(price) if price.isdigit() else 0
            restaurant_list.append(shop_data)
        
        return restaurant_list[:5] if len(restaurant_list)>=5 else restaurant_list + [
            {"é¤å…": "æ˜Ÿè‰ºä¼šå°ä¸å¿˜", "ç±»å‹": "ä¸­é¤", "è¯„åˆ†": 4.2, "äººå‡æ¶ˆè´¹(å…ƒ)": 15},
            {"é¤å…": "é«˜å³°æŸ æª¬é¸­", "ç±»å‹": "ä¸­é¤", "è¯„åˆ†": 4.5, "äººå‡æ¶ˆè´¹(å…ƒ)": 20},
            {"é¤å…": "å¤è®°è€å‹ç²‰", "ç±»å‹": "å¿«é¤", "è¯„åˆ†": 4.0, "äººå‡æ¶ˆè´¹(å…ƒ)": 25},
            {"é¤å…": "å¥½å‹ç¼˜", "ç±»å‹": "è‡ªåŠ©é¤", "è¯„åˆ†": 4.7, "äººå‡æ¶ˆè´¹(å…ƒ)": 35},
            {"é¤å…": "è¥¿å†·ç‰›æ’åº—", "ç±»å‹": "è¥¿é¤", "è¯„åˆ†": 4.3, "äººå‡æ¶ˆè´¹(å…ƒ)": 50}
        ][len(restaurant_list):5]
    
    @st.cache_data
    def preprocess_data():
        raw_data = crawl_restaurant_data()
        df_rest = pd.DataFrame(raw_data)
        df_rest["latitude"] = [22.853838, 22.965046, 22.812200, 22.809105, 22.839699]
        df_rest["longitude"] = [108.222177, 108.353921, 108.266629, 108.378664, 108.245804]
        df_rest["è¯„åˆ†"] = df_rest["è¯„åˆ†"].fillna(df_rest["è¯„åˆ†"].median()).clip(0,5)
        df_rest["äººå‡æ¶ˆè´¹(å…ƒ)"] = df_rest["äººå‡æ¶ˆè´¹(å…ƒ)"].fillna(df_rest["äººå‡æ¶ˆè´¹(å…ƒ)"].median()).clip(10,200)
        
        months = [f"{i}æœˆ" for i in range(1,13)]
        price_trend = {"æœˆä»½": months}
        for _, row in df_rest.iterrows():
            price_trend[row["é¤å…"]] = np.linspace(row["äººå‡æ¶ˆè´¹(å…ƒ)"]*0.95, row["äººå‡æ¶ˆè´¹(å…ƒ)"]*1.05, 12).round(1)
        df_trend = pd.DataFrame(price_trend)
        
        df_peak = pd.DataFrame({
            "æ—¶æ®µ": [f"{h}:00" for h in range(10,22)],
            "å®¢æµé‡": [50,80,120,150,200,180,160,220,250,200,150,100]
        })
        return df_rest, df_trend, df_peak
    
    df_rest, df_trend, df_peak = preprocess_data()
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("é¤å…åˆ†å¸ƒåœ°å›¾")
        st.map(df_rest[["latitude", "longitude"]], zoom=11)
    with col2:
        st.subheader("é¤å…è¯„åˆ†å¯¹æ¯”")
        st.bar_chart(df_rest, x="é¤å…", y="è¯„åˆ†", color="#1f77b4", use_container_width=True)
    
    col3, col4 = st.columns(2)
    with col3:
        st.subheader("ä¸åŒç±»å‹é¤å…äººå‡æ¶ˆè´¹")
        st.line_chart(df_rest, x="ç±»å‹", y="äººå‡æ¶ˆè´¹(å…ƒ)", color="#ff7f0e", use_container_width=True)
    with col4:
        st.subheader("5å®¶é¤å…12ä¸ªæœˆä»·æ ¼èµ°åŠ¿")
        st.line_chart(df_trend, x="æœˆä»½", y=df_rest["é¤å…"].tolist(), use_container_width=True)
    
    col5, col6 = st.columns(2)
    with col5:
        st.subheader("ç”¨é¤é«˜å³°æ—¶æ®µå®¢æµé‡")
        st.area_chart(df_peak, x="æ—¶æ®µ", y="å®¢æµé‡", color="#2ca02c", use_container_width=True)
    with col6:
        st.subheader("é¤å…è¯¦æƒ…è¡¨")
        st.dataframe(df_rest[["é¤å…", "ç±»å‹", "è¯„åˆ†", "äººå‡æ¶ˆè´¹(å…ƒ)"]], hide_index=True, use_container_width=True)

elif nav == "å­¦ç”Ÿæ•°å­—æ¡£æ¡ˆ":
    st.title("ğŸ“Š å­¦ç”Ÿ å‘¨å¥æ— -æ•°å­—æ¡£æ¡ˆ")
    
    st.header("ğŸ” åŸºç¡€ä¿¡æ¯")
    col1, col2 = st.columns([1, 3])
    with col2:
        st.markdown("""
        - **å­¦ç”ŸID:** NE0-2023-001
        - **å§“å:** å‘¨å¥æ—  
        - **æ³¨å†Œæ—¶é—´:** 2023-09-01  
        - **æŒ‡å¯¼æ•™å¸ˆ:** é™†ç´«å…‰ 
        - **å½“å‰ç­çº§:** 2022çº§ ä¿¡æ¯ç®¡ç†ä¿¡æ¯ç³»ç»Ÿ 2ç­  
        """)
    
    st.header("ğŸ’» æŠ€èƒ½çŸ©é˜µ")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Cç¼–ç¨‹", "95%", "2%")
    with col2:
        st.metric("Python", "87%", "-1%")
    with col3:
        st.metric("Java", "68%", "-3%")
    
    st.subheader("ğŸ“š Streamlitè¯¾ç¨‹è¿›åº¦")
    st.progress(78)
    st.text("Streamlitè¯¾ç¨‹è¿›åº¦: å·²å®Œæˆ78%")
    
    st.header("ğŸ“‹ ä»»åŠ¡æ—¥å¿—")
    
    tasks_data = {
        "ID": [0, 1, 2],
        "æ—¥æœŸ": ["2023-10-01", "2023-09-25", "2023-09-12"],
        "ä»»åŠ¡åç§°": ["å­¦ç”Ÿç®¡ç†ç³»ç»Ÿ", "è¯¾ç¨‹ç®¡ç†ç³»ç»Ÿ", "æ•°æ®å¯è§†åŒ–å±•ç¤º"],
        "çŠ¶æ€": ["âœ… å®Œæˆ", "ğŸ”„ è¿›è¡Œä¸­", "âŒ æœªå®Œæˆ"],
        "éš¾åº¦": ["â˜…â˜…â˜…â˜…â˜…", "â˜…â˜…â˜…â˜…â˜†", "â˜…â˜…â˜…â˜…â˜†"]
    }
    
    tasks_df = pd.DataFrame(tasks_data)
    st.table(tasks_df)
    
    st.header("ğŸ’¡ æœ€æ–°ä»£ç æˆæœ")
    code_example = """
    def attack_search():
        
        while True:
            if detect_vulnerability():
                exploit()
                return "ACCESS GRANTED"
            else:
                stealth_eval()
    """
    st.code(code_example, language="python")

